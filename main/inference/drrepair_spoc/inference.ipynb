{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import sqlite3\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "#sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))))\n",
    "os.chdir(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname('__file__'))))))))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "from models.seq2seq import Seq2seq\n",
    "from models.loss import Perplexity\n",
    "from models.optim import Optimizer\n",
    "from models import fields\n",
    "from evaluator.predictor import Predictor\n",
    "from util.helpers import tokens_to_source, compilation_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FORMAT = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, \"info\".upper()))\n",
    "\n",
    "rnn = \"lstm\"\n",
    "data_name = \"DrRepair_spoc\"\n",
    "data_type = \"raw\"\n",
    "pretrained_dir_name = None\n",
    "select = \"1\"\n",
    "batch_size = 64\n",
    "\n",
    "train_path = \"data/\"+data_name+\"/data_train.txt\"\n",
    "test_path = \"data/deepfix_raw_data\"\n",
    "config_path = \"models/config.json\"\n",
    "\n",
    "target_vocab_path = \"data_processing/\"+data_name+\"/target_vocab.json\"\n",
    "inverse_vocab_path = \"data_processing/\"+data_name+\"/target_vocab_reverse.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 400\n",
    "src = fields.SourceField()\n",
    "tgt = fields.TargetField()\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_path, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)],\n",
    "    filter_pred=len_filter)\n",
    "src.build_vocab(train)\n",
    "tgt.build_vocab(train)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab\n",
    "\n",
    "weight = torch.ones(len(tgt.vocab))\n",
    "pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "loss = Perplexity(weight, pad)\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()\n",
    "\n",
    "optimizer = \"Adam\"\n",
    "seq2seq = None\n",
    "config_json = open(config_path).read()\n",
    "config = json.loads(config_json)\n",
    "print(json.dumps(config, indent=4))\n",
    "\n",
    "save_path = (data_name\n",
    "                + (\"_att\" if config[\"use_attention\"] else \"\")\n",
    "                + (\"_with_pos_\" + config[\"position_embedding\"]\n",
    "                    if config[\"position_embedding\"] is not None else \"\")\n",
    "                + (\"_cat\" if config[\"pos_add\"] == \"cat\" else \"\")\n",
    "                + \"_emb\" + str(config[\"embedding_size\"])\n",
    "                + \"_hidden\" + str(config[\"hidden_size\"])\n",
    "                + (\"_bi\" if config[\"bidirectional\"] else \"\")\n",
    "                + (\"_\" + str(config[\"n_layers\"]) if config[\"n_layers\"] != 1 else \"\"))\n",
    "print(\"Save_path : %s\" % save_path)\n",
    "\n",
    "seq2seq = Seq2seq(config, len(src.vocab), tgt.vocab, tgt.sos_id, tgt.eos_id)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    seq2seq.cuda()\n",
    "\n",
    "for param in seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "log_path = \"log/pth/\"+save_path +\"_\" + rnn + \"_\" + str(select) + \"_model_save.pth\"\n",
    "\n",
    "#seq2seq.load_state_dict(torch.load(log_path))\n",
    "seq2seq.load_state_dict(torch.load(log_path, map_location=\"cpu\"))\n",
    "seq2seq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(seq2seq, input_vocab, output_vocab, output_vocab.stoi[train.fields['tgt'].pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fix(program):\n",
    "    tgt_seq = predictor.predict_batch(program)\n",
    "    return tgt_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(inverse_vocab_path, \"r\") as json_file:\n",
    "    inverse_vocab = json.load(json_file)\n",
    "    \n",
    "with open(target_vocab_path, \"r\") as json_file:\n",
    "    target_vocab = json.load(json_file)\n",
    "    \n",
    "def is_replace_edit(edit):\n",
    "    return str(edit) in target_vocab['replace'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_edits(source, edits):\n",
    "    fixed = []\n",
    "    inserted = 0\n",
    "\n",
    "    for i, edit in enumerate(edits):\n",
    "        if i - inserted >= len(source):\n",
    "            break\n",
    "        if edit == '0':\n",
    "            fixed.append(source[i - inserted])\n",
    "        elif edit != '-1':\n",
    "            fixed.append(inverse_vocab[edit])\n",
    "            if not is_replace_edit(edits[i]):\n",
    "                inserted += 1\n",
    "    return fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"data/\"+data_name+\"/data_val.txt\", 'r') as f:\n",
    "    data = f.read()\n",
    "val = data.split('\\n')[:-1]\n",
    "rad_val = random.choice(val)\n",
    "\n",
    "prediction_result = get_fix([rad_val.split('\\t')[0].split()])\n",
    "\n",
    "corrupt_name_dict = dict()\n",
    "for i in rad_val.split('\\t')[0].split():\n",
    "    if '_<id>_' in i and i not in corrupt_name_dict.keys():\n",
    "        corrupt_name_dict[i] = \"ID_\" + i.split('_')[2].split('@')[0]\n",
    "corrupt_code = tokens_to_source(rad_val.split('\\t')[0], corrupt_name_dict, False)\n",
    "corrupt_code = corrupt_code.replace(';', ';\\n')\n",
    "corrupt_code = corrupt_code.replace('{', '{\\n')\n",
    "corrupt_code = corrupt_code.replace('}', '}\\n')\n",
    "\n",
    "orig_data = apply_edits(rad_val.split('\\t')[0].split(), rad_val.split('\\t')[1].split())\n",
    "orig_name_dict = dict()\n",
    "for i in orig_data:\n",
    "    if '_<id>_' in i and i not in orig_name_dict.keys():\n",
    "        orig_name_dict[i] = \"ID_\" + i.split('_')[2].split('@')[0]\n",
    "orig_code = tokens_to_source(' '.join(orig_data), orig_name_dict, False)\n",
    "orig_code = orig_code.replace(';', ';\\n')\n",
    "orig_code = orig_code.replace('{', '{\\n')\n",
    "orig_code = orig_code.replace('}', '}\\n')\n",
    "\n",
    "print(\"[Corrupt Data]\\n{}\".format(rad_val.split('\\t')[0]))\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"[Corrupt Code]\\n{}\".format(corrupt_code))\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"[Origin Code]\\n{}\".format(orig_code))\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"[Corrupt Target]\\n{}\".format(rad_val.split('\\t')[1]))\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"[Predict Result]\\n{}\".format(prediction_result[0]))\n",
    "print(\"------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
